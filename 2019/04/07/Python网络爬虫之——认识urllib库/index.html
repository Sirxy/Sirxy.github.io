<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python网络爬虫之——认识urllib库 | 沐雨橙风</title>
  <meta name="author" content="Sirxy">
  
  <meta name="description" content="Python, web后端，web前端，数据库，Linux等编程技术博客总结">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Python网络爬虫之——认识urllib库"/>
  <meta property="og:site_name" content="沐雨橙风"/>

  
    <meta property="og:image" content=""/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="沐雨橙风" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">沐雨橙风</a></h1>
  <h2><a href="/">水滴石穿</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2019-04-07T04:22:58.000Z"><a href="/2019/04/07/Python网络爬虫之——认识urllib库/">2019-04-07</a></time>
      
      
  
    <h1 class="title">Python网络爬虫之——认识urllib库</h1>
  

    </header>
    <div class="entry">
      
        <p>不说废话，耿直，直接上案例。<br><a id="more"></a></p>
<h3 id="案例1：百度首页爬取"><a href="#案例1：百度首页爬取" class="headerlink" title="案例1：百度首页爬取"></a>案例1：百度首页爬取</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#  导包</span><br><span class="line">from urllib import request</span><br><span class="line"># 确定爬取资源</span><br><span class="line">base_url = &apos;http://www.baidu.com&apos;</span><br><span class="line"># 构建请求 发送请求</span><br><span class="line">response = request.urlopen(base_url)</span><br><span class="line"># 接受响应信息</span><br><span class="line">html = response.read().decode(&apos;utf-8&apos;)</span><br><span class="line">print(html)   # 返回的是html源代码  </span><br><span class="line"># 信息存储</span><br><span class="line">with open(&apos;./baidu.html&apos;,&apos;w&apos;,encodeing=&apos;utf-8&apos;) as f:</span><br><span class="line">    f.wirte(html) </span><br><span class="line">```   </span><br><span class="line"></span><br><span class="line">### 案例2：get请求中url带中文字符</span><br><span class="line"></span><br><span class="line">实现百度搜索。url地址会将url中的中文字符进行编码，所以当我们使用urllib发送此类url请求前要讲中文字符进行编码。</span><br></pre></td></tr></table></figure>
<p>from urllib import request, parse #  1.导包<br>base_url = ‘<a href="http://www.baidu.com/s?&#39;" target="_blank" rel="noopener">http://www.baidu.com/s?&#39;</a> # 2.确定爬取资源<br>inp = input(‘输入搜索内容:’)<br>msg = { # 3.构造请求参数<br>    ‘wd’: inp<br>}<br>encodemsg = parse.urlencode(msg)<br>newurl = base_url+encodemsg # 将编码后的参数进行拼接<br>response = request.urlopen(newurl) #4. 构建请求 发送请求<br>html = response.read().decode(‘utf-8’) # 5.接受响应信息<br>print(html)   # 返回的是html源代码<br>with open(‘./baidu.html’, ‘w’, encodeing=’utf-8’) as f: # 信息存储<br>    f.wirte(html)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 案例3：带user-agent反爬的网站</span><br><span class="line"></span><br><span class="line">带有user-agent反爬的网站在发送请求之前必须要构建自己的请求头。</span><br></pre></td></tr></table></figure></p>
<p>from urllib import request # 1.导包<br>base_url = ‘<a href="http://www.xicidaili.com&#39;" target="_blank" rel="noopener">http://www.xicidaili.com&#39;</a> # 2.确定爬取资源<br>headers = { # 3.构造请求头与请求<br>    ‘User-Agent’: ‘Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36’<br>}<br>req = request.Request(url=base_url, headers=headers)<br>html = request.urlopen(req) # 4.发送请求<br>with open(‘./xici.html’,’w’,encodeing=’utf-8’) as f: # 5.接受并存储信息<br>    f.write(html)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 案例4：以上都是get请求 接下来做百度翻译(post请求)</span><br><span class="line"></span><br><span class="line">先通过抓包工具F12 newwork分析，找到翻译时发送的请求，因为是异步请求又是post请求，所以还要找到传递的参数。直接上代码：</span><br></pre></td></tr></table></figure></p>
<p>from urllib import request,parse<br>import ssl,json<br>ssl._create_default_https_context = ssl._create_unverified_context</p>
<h1 id="确定爬取地址"><a href="#确定爬取地址" class="headerlink" title="确定爬取地址"></a>确定爬取地址</h1><p>base_url = ‘<a href="https://fanyi.baidu.com/sug&#39;" target="_blank" rel="noopener">https://fanyi.baidu.com/sug&#39;</a><br>def fanyi(msg):<br>    dataform = { # 构造数据<br>        ‘kw’: msg<br>    }<br>    newdataform = parse.urlencode(dataform)<br>    response =  request.urlopen(url=base_url, data=bytes(newdataform, encoding=’utf-8’)) # 发送请求<br>    res = response.read().decode(‘utf-8’) # 接受返回的数据<br>    newres = json.loads(res)</p>
<pre><code># print(json.loads(res), type(json.loads(res)))
str = &apos;&apos;
for item in newres[&apos;data&apos;]:
    str += item[&apos;v&apos;] + &apos;\n&apos;
print(str)
</code></pre><h1 id="print-json-dumps-newres-indent-4-ensure-ascii-False-将字典类型转换成字符串"><a href="#print-json-dumps-newres-indent-4-ensure-ascii-False-将字典类型转换成字符串" class="headerlink" title="print(json.dumps(newres, indent=4, ensure_ascii=False)) # 将字典类型转换成字符串"></a>print(json.dumps(newres, indent=4, ensure_ascii=False)) # 将字典类型转换成字符串</h1><p>if <strong>name</strong> == “<strong>main</strong>“:<br>    while True:<br>        msg = input(‘请输入要翻译的单词：’)<br>        if msg == ‘q’:  # 按q退出<br>            break<br>        fanyi(msg)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">注意：如果发送请求时出现如下错误：</span><br></pre></td></tr></table></figure></p>
<p>urllib.error.URLError: <urlopen error="" [ssl:="" certificate_verify_failed]="" certificate="" verify="" failed="" (_ssl.c:777)=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这是因为ssl 验证的错误，可以将下面代码粘贴，解决不进行验证：</span><br></pre></td></tr></table></figure></urlopen></p>
<p>ssl._create_default_https_context = ssl._create_unverified_context<br><code>`</code></p>
<p>练习：爬取百度贴吧，根据用户输入的贴吧名称，页码范围来爬取指定贴吧指定页数范围。<br>爬取豆瓣电影的数据，这个是豆瓣电影的api:<a href="https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=" target="_blank" rel="noopener">https://movie.douban.com/typerank?type_name=%E5%89%A7%E6%83%85&amp;type=11&amp;interval_id=100:90&amp;action=</a></p>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/爬虫/">爬虫</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Python爬虫/">Python爬虫</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
      <div id="fb-root"></div>
<script>
  (function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345";
    fjs.parentNode.insertBefore(js, fjs);
  }(document, 'script', 'facebook-jssdk'));
</script>

<div class="fb-comments" data-href="http://sirxy.github.io/2019/04/07/Python网络爬虫之——认识urllib库/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div>
      
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:sirxy.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/HTTP/">HTTP</a><small>3</small></li>
  
    <li><a href="/categories/Linux/">Linux</a><small>1</small></li>
  
    <li><a href="/categories/Python/">Python</a><small>3</small></li>
  
    <li><a href="/categories/Python基础/">Python基础</a><small>1</small></li>
  
    <li><a href="/categories/Python面向对象/">Python面向对象</a><small>2</small></li>
  
    <li><a href="/categories/nginx/">nginx</a><small>3</small></li>
  
    <li><a href="/categories/web前端/">web前端</a><small>1</small></li>
  
    <li><a href="/categories/Python/内置模块/">内置模块</a><small>3</small></li>
  
    <li><a href="/categories/多线程编程/">多线程编程</a><small>1</small></li>
  
    <li><a href="/categories/爬虫/">爬虫</a><small>1</small></li>
  
    <li><a href="/categories/版本控制/">版本控制</a><small>1</small></li>
  
    <li><a href="/categories/网络协议/">网络协议</a><small>1</small></li>
  
    <li><a href="/categories/网络通信/">网络通信</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/HTML5-CSS3/">HTML5/CSS3</a><small>1</small></li>
  
    <li><a href="/tags/HTTP学习/">HTTP学习</a><small>3</small></li>
  
    <li><a href="/tags/Linux/">Linux</a><small>1</small></li>
  
    <li><a href="/tags/Nginx学习/">Nginx学习</a><small>3</small></li>
  
    <li><a href="/tags/Python基础/">Python基础</a><small>2</small></li>
  
    <li><a href="/tags/Python模块/">Python模块</a><small>2</small></li>
  
    <li><a href="/tags/Python爬虫/">Python爬虫</a><small>1</small></li>
  
    <li><a href="/tags/Python线程与进程/">Python线程与进程</a><small>1</small></li>
  
    <li><a href="/tags/Python面向对象/">Python面向对象</a><small>2</small></li>
  
    <li><a href="/tags/git版本控制/">git版本控制</a><small>1</small></li>
  
    <li><a href="/tags/网络协议学习/">网络协议学习</a><small>1</small></li>
  
    <li><a href="/tags/网络通信学习/">网络通信学习</a><small>1</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2019 Sirxy
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
